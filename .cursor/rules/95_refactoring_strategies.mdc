---
alwaysApply: true
---
# Safe Refactoring Patterns and Strategies

## Overview

This rule defines comprehensive strategies for safe, incremental code refactoring. Refactoring improves code quality without changing external behavior, requiring systematic approaches to maintain stability and functionality.

## Refactoring Safety Principles

### Core Safety Requirements

**Behavioral Preservation**:
- [ ] **External Behavior**: Refactoring must not change observable system behavior
- [ ] **API Contracts**: Public interfaces remain unchanged
- [ ] **Data Integrity**: Data transformations preserve correctness
- [ ] **Performance Characteristics**: Performance profiles remain acceptable
- [ ] **Error Handling**: Error conditions and handling remain consistent

**Safety Assessment Framework**:
```python
REFACTORING_SAFETY_CHECKLIST = {
    'behavioral_preservation': {
        'api_compatibility': 'Public APIs unchanged and compatible',
        'data_consistency': 'Data transformations preserve meaning',
        'error_handling': 'Error conditions handled appropriately',
        'performance_bounds': 'Performance within acceptable limits'
    },
    'testing_coverage': {
        'unit_tests': 'Unit tests pass and cover refactored code',
        'integration_tests': 'Integration tests validate system behavior',
        'regression_tests': 'Regression tests prevent functionality loss',
        'performance_tests': 'Performance tests ensure acceptable degradation'
    },
    'code_quality_improvement': {
        'readability': 'Code is more readable and maintainable',
        'modularity': 'Code is better organized and modular',
        'technical_debt': 'Technical debt is reduced',
        'future_maintainability': 'Code is easier to modify in future'
    },
    'risk_mitigation': {
        'rollback_plan': 'Clear rollback strategy exists',
        'incremental_changes': 'Changes can be applied incrementally',
        'feature_flags': 'New functionality can be toggled',
        'monitoring_alerts': 'System monitoring detects issues early'
    }
}

def assess_refactoring_safety(refactoring_plan, codebase_context):
    """Assess the safety of a proposed refactoring"""

    safety_assessment = {}

    for safety_category, safety_checks in REFACTORING_SAFETY_CHECKLIST.items():
        category_assessment = {}

        for check_name, check_description in safety_checks.items():
            assessment_result = evaluate_safety_check(
                check_name, check_description, refactoring_plan, codebase_context
            )

            category_assessment[check_name] = {
                'description': check_description,
                'assessment': assessment_result,
                'risk_level': determine_risk_level(assessment_result),
                'mitigation_required': assessment_result['requires_mitigation']
            }

        safety_assessment[safety_category] = {
            'checks': category_assessment,
            'overall_risk': calculate_category_risk(category_assessment),
            'safety_score': calculate_category_safety_score(category_assessment)
        }

    overall_safety_score = calculate_overall_safety_score(safety_assessment)

    return {
        'assessment': safety_assessment,
        'overall_safety_score': overall_safety_score,
        'safety_rating': determine_safety_rating(overall_safety_score),
        'required_mitigations': identify_required_mitigations(safety_assessment),
        'recommended_approach': recommend_refactoring_approach(overall_safety_score)
    }
```

## Incremental Refactoring Patterns

### Change Granularity Levels

**Atomic Refactoring (Level 1)**:
**Scope**: Single method, variable rename, or small extraction
**Duration**: 5-15 minutes
**Risk Level**: Very Low
**Examples**:
- Rename variable or method
- Extract constant
- Inline temporary variable
- Reorder method parameters

**Component Refactoring (Level 2)**:
**Scope**: Single class or module
**Duration**: 30-60 minutes
**Risk Level**: Low
**Examples**:
- Extract class
- Move method between classes
- Replace conditional with polymorphism
- Introduce parameter object

**System Refactoring (Level 3)**:
**Scope**: Multiple components or architectural changes
**Duration**: 2-4 hours
**Risk Level**: Medium
**Examples**:
- Extract microservice
- Replace inheritance with composition
- Introduce event-driven architecture
- Database schema refactoring

**Enterprise Refactoring (Level 4)**:
**Scope**: System-wide changes affecting multiple teams
**Duration**: Days to weeks
**Risk Level**: High
**Examples**:
- Framework migration
- Architecture modernization
- Large-scale pattern replacement
- Technology stack replacement

### Incremental Refactoring Workflow

**Step-by-Step Process**:
```python
def execute_incremental_refactoring(refactoring_plan, codebase_state):
    """Execute refactoring in safe, incremental steps"""

    # Step 1: Preparation
    preparation_result = prepare_refactoring_environment(
        refactoring_plan, codebase_state
    )

    if not preparation_result['ready']:
        return {'status': 'failed', 'reason': preparation_result['blockers']}

    # Step 2: Break down into atomic changes
    atomic_changes = decompose_into_atomic_changes(refactoring_plan)

    # Step 3: Validate each change
    validated_changes = []
    for change in atomic_changes:
        validation_result = validate_atomic_change(change, codebase_state)

        if validation_result['safe']:
            validated_changes.append({
                'change': change,
                'validation': validation_result,
                'rollback_plan': create_rollback_plan(change)
            })
        else:
            # Handle validation failure
            handle_validation_failure(change, validation_result)

    # Step 4: Execute changes incrementally
    execution_results = []
    for validated_change in validated_changes:
        execution_result = execute_validated_change(validated_change)

        execution_results.append(execution_result)

        # Check for issues after each change
        if execution_result['status'] == 'failed':
            # Execute rollback
            rollback_result = execute_rollback(validated_change['rollback_plan'])
            break

        # Run validation tests
        test_result = run_validation_tests(validated_change)
        if not test_result['passed']:
            # Execute rollback and stop
            rollback_result = execute_rollback(validated_change['rollback_plan'])
            break

    # Step 5: Final validation
    final_validation = perform_final_validation(refactoring_plan, execution_results)

    return {
        'status': 'completed' if final_validation['passed'] else 'failed',
        'execution_results': execution_results,
        'final_validation': final_validation,
        'rollback_actions_taken': len([r for r in execution_results if r.get('rolled_back')])
    }
```

## Testing During Refactoring

### Test-First Refactoring Approach

**Refactoring Test Strategy**:
```python
REFACTORING_TEST_STRATEGY = {
    'preservation_tests': {
        'purpose': 'Ensure behavior is preserved during refactoring',
        'scope': 'All existing functionality',
        'execution': 'Run before and after each refactoring step',
        'failure_action': 'Stop refactoring, rollback changes'
    },
    'regression_tests': {
        'purpose': 'Detect unintended side effects',
        'scope': 'Related functionality and integration points',
        'execution': 'Continuous execution during refactoring',
        'failure_action': 'Investigate and fix or rollback'
    },
    'performance_tests': {
        'purpose': 'Ensure performance characteristics are maintained',
        'scope': 'Performance-critical code paths',
        'execution': 'Benchmark before and after refactoring',
        'failure_action': 'Optimize or rollback if degradation > 10%'
    },
    'integration_tests': {
        'purpose': 'Validate system integration after structural changes',
        'scope': 'Component interactions and data flows',
        'execution': 'After each major refactoring milestone',
        'failure_action': 'Fix integration issues or rollback'
    }
}

def implement_refactoring_test_strategy(refactoring_plan, existing_tests):
    """Implement comprehensive testing strategy for refactoring"""

    # Analyze existing test coverage
    test_coverage_analysis = analyze_existing_test_coverage(existing_tests, refactoring_plan)

    # Identify testing gaps
    testing_gaps = identify_testing_gaps(test_coverage_analysis, refactoring_plan)

    # Generate additional tests
    additional_tests = generate_refactoring_tests(testing_gaps, refactoring_plan)

    # Create test execution plan
    test_execution_plan = create_test_execution_plan(
        existing_tests, additional_tests, refactoring_plan
    )

    # Set up test automation
    test_automation = setup_test_automation(test_execution_plan)

    return {
        'coverage_analysis': test_coverage_analysis,
        'testing_gaps': testing_gaps,
        'additional_tests': additional_tests,
        'execution_plan': test_execution_plan,
        'automation_setup': test_automation,
        'confidence_level': calculate_testing_confidence(test_coverage_analysis, additional_tests)
    }
```

### Test Preservation Techniques

**Characterization Tests**:
```python
def create_characterization_tests(codebase_component, test_framework):
    """Create tests that characterize existing behavior"""

    # Analyze component interface
    interface_analysis = analyze_component_interface(codebase_component)

    # Generate characterization tests
    characterization_tests = []

    for interface_method in interface_analysis['methods']:
        test_cases = generate_method_characterization_tests(
            interface_method, codebase_component
        )

        characterization_tests.extend(test_cases)

    # Generate integration characterization tests
    integration_tests = generate_integration_characterization_tests(
        interface_analysis, codebase_component
    )

    characterization_tests.extend(integration_tests)

    # Format tests for target framework
    formatted_tests = format_tests_for_framework(
        characterization_tests, test_framework
    )

    return {
        'tests': formatted_tests,
        'coverage': calculate_characterization_coverage(formatted_tests, interface_analysis),
        'execution_plan': create_characterization_test_execution_plan(formatted_tests)
    }
```

## Backward Compatibility Management

### Compatibility Assessment Framework

**Compatibility Dimensions**:
```python
COMPATIBILITY_DIMENSIONS = {
    'api_compatibility': {
        'interface_signatures': 'Method signatures unchanged',
        'return_types': 'Return types remain compatible',
        'parameter_types': 'Parameter types remain compatible',
        'exception_types': 'Exceptions remain compatible'
    },
    'data_compatibility': {
        'schema_compatibility': 'Data schemas remain compatible',
        'serialization_formats': 'Data formats remain readable',
        'migration_paths': 'Data migration is supported',
        'rollback_compatibility': 'Can rollback without data loss'
    },
    'behavioral_compatibility': {
        'functional_behavior': 'Functional behavior unchanged',
        'performance_characteristics': 'Performance within acceptable bounds',
        'error_conditions': 'Error handling remains consistent',
        'edge_cases': 'Edge case handling preserved'
    },
    'deployment_compatibility': {
        'zero_downtime_deployment': 'Can deploy without service interruption',
        'rolling_deployment': 'Can deploy incrementally',
        'rollback_capability': 'Can rollback safely',
        'resource_compatibility': 'Resource requirements compatible'
    }
}

def assess_backward_compatibility(refactoring_changes, existing_systems):
    """Assess backward compatibility impact of refactoring"""

    compatibility_assessment = {}

    for dimension, compatibility_checks in COMPATIBILITY_DIMENSIONS.items():
        dimension_assessment = {}

        for check_name, check_description in compatibility_checks.items():
            assessment_result = evaluate_compatibility_impact(
                check_name, check_description, refactoring_changes, existing_systems
            )

            dimension_assessment[check_name] = {
                'description': check_description,
                'impact': assessment_result['impact_level'],
                'breaking_changes': assessment_result['breaking_changes'],
                'mitigation_required': assessment_result['requires_mitigation'],
                'migration_path': assessment_result.get('migration_path', [])
            }

        compatibility_assessment[dimension] = {
            'checks': dimension_assessment,
            'breaking_change_count': count_breaking_changes(dimension_assessment),
            'compatibility_score': calculate_dimension_compatibility_score(dimension_assessment),
            'migration_complexity': assess_migration_complexity(dimension_assessment)
        }

    overall_compatibility_score = calculate_overall_compatibility_score(compatibility_assessment)

    return {
        'assessment': compatibility_assessment,
        'overall_score': overall_compatibility_score,
        'compatibility_rating': determine_compatibility_rating(overall_compatibility_score),
        'breaking_changes': identify_all_breaking_changes(compatibility_assessment),
        'migration_plan': generate_compatibility_migration_plan(compatibility_assessment)
    }
```

### Compatibility Preservation Techniques

**Interface Adapters**:
```python
def create_interface_adapters(breaking_changes, compatibility_requirements):
    """Create adapters to maintain backward compatibility"""

    adapters = {}

    for breaking_change in breaking_changes:
        if breaking_change['type'] == 'method_signature_change':
            adapters[breaking_change['component']] = create_method_adapter(
                breaking_change, compatibility_requirements
            )
        elif breaking_change['type'] == 'class_interface_change':
            adapters[breaking_change['component']] = create_class_adapter(
                breaking_change, compatibility_requirements
            )
        elif breaking_change['type'] == 'data_format_change':
            adapters[breaking_change['component']] = create_data_adapter(
                breaking_change, compatibility_requirements
            )

    # Generate adapter implementation
    adapter_implementation = generate_adapter_implementation(adapters)

    # Create adapter tests
    adapter_tests = generate_adapter_tests(adapters, compatibility_requirements)

    return {
        'adapters': adapters,
        'implementation': adapter_implementation,
        'tests': adapter_tests,
        'deployment_plan': create_adapter_deployment_plan(adapters)
    }
```

## Refactoring Validation and Verification

### Post-Refactoring Validation

**Validation Checklist**:
- [ ] **Functional Testing**: All functionality works as expected
- [ ] **Performance Testing**: Performance meets requirements
- [ ] **Integration Testing**: System integration works correctly
- [ ] **Compatibility Testing**: Backward compatibility maintained
- [ ] **Load Testing**: System handles expected load
- [ ] **Security Testing**: Security properties preserved
- [ ] **User Acceptance Testing**: End users accept changes

**Automated Validation Framework**:
```python
def execute_post_refactoring_validation(refactoring_plan, validation_requirements):
    """Execute comprehensive post-refactoring validation"""

    validation_results = {}

    # Functional validation
    functional_validation = execute_functional_validation(refactoring_plan)
    validation_results['functional'] = functional_validation

    # Performance validation
    performance_validation = execute_performance_validation(refactoring_plan)
    validation_results['performance'] = performance_validation

    # Integration validation
    integration_validation = execute_integration_validation(refactoring_plan)
    validation_results['integration'] = integration_validation

    # Compatibility validation
    compatibility_validation = execute_compatibility_validation(refactoring_plan)
    validation_results['compatibility'] = compatibility_validation

    # Security validation
    security_validation = execute_security_validation(refactoring_plan)
    validation_results['security'] = security_validation

    # Calculate overall validation score
    overall_validation_score = calculate_validation_score(validation_results)

    # Generate validation report
    validation_report = generate_validation_report(
        validation_results, overall_validation_score, refactoring_plan
    )

    return {
        'results': validation_results,
        'overall_score': overall_validation_score,
        'validation_status': determine_validation_status(overall_validation_score),
        'report': validation_report,
        'recommendations': generate_validation_recommendations(validation_results)
    }
```

## Refactoring Types and Strategies

### Code Structure Refactoring

**Method-Level Refactoring**:
- **Extract Method**: Break down large methods into smaller, focused methods
- **Inline Method**: Replace method call with method body when appropriate
- **Rename Method**: Improve method names for clarity
- **Add Parameter**: Extend method interface with new parameters
- **Remove Parameter**: Simplify method interface by removing unused parameters

**Class-Level Refactoring**:
- **Extract Class**: Create new class from part of existing class
- **Inline Class**: Merge class into another class when appropriate
- **Move Method**: Move method to more appropriate class
- **Move Field**: Move field to more appropriate class
- **Replace Data Value with Object**: Replace primitive with object

### Architecture Refactoring

**Component Reorganization**:
```python
def plan_component_reorganization(current_architecture, target_architecture):
    """Plan safe component reorganization refactoring"""

    # Analyze current component structure
    current_analysis = analyze_component_structure(current_architecture)

    # Define target component structure
    target_analysis = analyze_component_structure(target_architecture)

    # Identify reorganization steps
    reorganization_steps = identify_reorganization_steps(
        current_analysis, target_analysis
    )

    # Assess dependencies and impacts
    dependency_analysis = analyze_reorganization_dependencies(
        reorganization_steps, current_architecture
    )

    # Create safe migration plan
    migration_plan = create_safe_migration_plan(
        reorganization_steps, dependency_analysis
    )

    return {
        'current_analysis': current_analysis,
        'target_analysis': target_analysis,
        'reorganization_steps': reorganization_steps,
        'dependency_analysis': dependency_analysis,
        'migration_plan': migration_plan,
        'risk_assessment': assess_reorganization_risks(migration_plan)
    }
```

### Data Refactoring

**Database Schema Refactoring**:
- **Add Column**: Add new column to existing table
- **Remove Column**: Remove unused column
- **Rename Column**: Rename column for clarity
- **Change Column Type**: Modify column data type
- **Split Table**: Divide table into multiple tables
- **Merge Tables**: Combine multiple tables into one

**Data Migration Strategies**:
```python
def plan_database_refactoring(schema_changes, data_migration_strategy):
    """Plan safe database refactoring with data migration"""

    # Analyze schema changes
    schema_analysis = analyze_schema_changes(schema_changes)

    # Assess data migration complexity
    migration_complexity = assess_migration_complexity(schema_changes)

    # Create migration scripts
    migration_scripts = generate_migration_scripts(schema_changes, data_migration_strategy)

    # Plan rollback strategy
    rollback_strategy = create_migration_rollback_strategy(migration_scripts)

    # Validate migration safety
    migration_validation = validate_migration_safety(
        migration_scripts, rollback_strategy, schema_analysis
    )

    return {
        'schema_analysis': schema_analysis,
        'migration_complexity': migration_complexity,
        'migration_scripts': migration_scripts,
        'rollback_strategy': rollback_strategy,
        'validation_results': migration_validation,
        'execution_plan': create_migration_execution_plan(migration_scripts, rollback_strategy)
    }
```

## Risk Assessment and Mitigation

### Refactoring Risk Assessment

**Risk Factors**:
```python
REFACTORING_RISK_FACTORS = {
    'code_complexity': {
        'cyclomatic_complexity': 'High complexity increases risk',
        'code_age': 'Older code may have undocumented dependencies',
        'test_coverage': 'Low coverage increases undetected regression risk',
        'team_familiarity': 'Unfamiliar code increases error likelihood'
    },
    'system_impact': {
        'usage_frequency': 'Frequently used code has higher impact',
        'critical_path': 'Code on critical path has higher risk',
        'external_dependencies': 'External dependencies increase integration risk',
        'performance_sensitivity': 'Performance-critical code has higher risk'
    },
    'organizational_factors': {
        'team_size': 'Smaller teams have higher coordination risk',
        'time_pressure': 'Time pressure increases error likelihood',
        'stakeholder_count': 'More stakeholders increase coordination complexity',
        'rollback_complexity': 'Complex rollback increases risk'
    },
    'technical_factors': {
        'dependency_complexity': 'Complex dependencies increase risk',
        'interface_stability': 'Unstable interfaces increase breaking change risk',
        'data_volume': 'Large data volumes increase migration risk',
        'legacy_technology': 'Legacy technology may have unknown behaviors'
    }
}

def assess_refactoring_risks(refactoring_plan, codebase_context, team_context):
    """Assess comprehensive risks for refactoring project"""

    risk_assessment = {}

    for risk_category, risk_factors in REFACTORING_RISK_FACTORS.items():
        category_risks = {}

        for risk_factor, risk_description in risk_factors.items():
            risk_level = evaluate_risk_factor(
                risk_factor, risk_description, refactoring_plan,
                codebase_context, team_context
            )

            category_risks[risk_factor] = {
                'description': risk_description,
                'level': risk_level,
                'impact': calculate_risk_impact(risk_level, risk_factor),
                'mitigation_strategies': identify_risk_mitigations(risk_factor, risk_level)
            }

        risk_assessment[risk_category] = {
            'risks': category_risks,
            'category_risk_score': calculate_category_risk_score(category_risks),
            'high_priority_risks': identify_high_priority_risks(category_risks)
        }

    overall_risk_score = calculate_overall_risk_score(risk_assessment)

    return {
        'assessment': risk_assessment,
        'overall_score': overall_risk_score,
        'risk_rating': determine_risk_rating(overall_risk_score),
        'mitigation_plan': generate_comprehensive_mitigation_plan(risk_assessment),
        'contingency_plan': create_risk_contingency_plan(risk_assessment)
    }
```

### Risk Mitigation Strategies

**Preventive Mitigation**:
- Comprehensive testing before refactoring
- Feature flags for gradual rollout
- Detailed documentation of changes
- Team training on refactored code

**Reactive Mitigation**:
- Automated rollback procedures
- Monitoring and alerting for issues
- Incremental deployment strategies
- Emergency response procedures

**Continuous Mitigation**:
- Regular risk reassessment
- Progress monitoring and adjustment
- Stakeholder communication
- Success metric tracking

This comprehensive refactoring framework ensures safe, incremental, and well-validated code improvements that maintain system stability and functionality while enhancing code quality and maintainability.